<!DOCTYPE html>


<html class="writer-html5" lang="en" >
<!-- Copyright (C) 2020-2022, Marek Gagolewski <https://www.gagolewski.com> -->

<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Basics &mdash; Python and R Package genieclust</title>
  

  
  
  <script async defer src="https://buttons.github.io/buttons.js"></script>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/plot_directive.css" type="text/css" />
  <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../_static/favicon.png"/>
  

  
  

  
    <link rel="canonical" href="https://genieclust.gagolewski.com/weave/basics.html" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Comparing Algorithms on Toy Datasets" href="sklearn_toy_example.html" />
    <link rel="prev" title="genieclust: Fast and Robust Hierarchical Clustering with Noise Point Detection" href="../index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html"> genieclust
          

          
          </a>

          <div class="version">
              Python and R Package<br />    v1.1.1
          </div>

<!--
          
            
            
              <div class="version">
                by Marek Gagolewski
              </div>
            
          
-->

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search phrase..." />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">genieclust</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">About</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.gagolewski.com/">Author</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/gagolews/genieclust">Source Code (GitHub)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/gagolews/genieclust/issues">Bug Tracker and Feature Suggestions</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/genieclust/">PyPI Entry</a></li>
<li class="toctree-l1"><a class="reference external" href="https://CRAN.R-project.org/package=genieclust">CRAN Entry</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples and Tutorials</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Basics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#breaking-the-ice">Breaking the Ice</a></li>
<li class="toctree-l2"><a class="reference internal" href="#a-comparison-with-k-means">A Comparison with k-means</a></li>
<li class="toctree-l2"><a class="reference internal" href="#a-comparison-with-hdbscan">A Comparison with HDBSCAN*</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dendrograms">Dendrograms</a></li>
<li class="toctree-l2"><a class="reference internal" href="#further-reading">Further Reading</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="sklearn_toy_example.html">Comparing Algorithms on Toy Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks_ar.html">Benchmarks (How Good Is It?)</a></li>
<li class="toctree-l1"><a class="reference internal" href="timings.html">Timings (How Fast Is It?)</a></li>
<li class="toctree-l1"><a class="reference internal" href="noise.html">Clustering with Noise Points Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">Example: Sparse Data and Movie Recommendation</a></li>
<li class="toctree-l1"><a class="reference internal" href="string.html">Example: String Data and Grouping of DNA</a></li>
<li class="toctree-l1"><a class="reference internal" href="r.html">R Interface Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../genieclust.html">Python Package <cite>genieclust</cite> Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rapi.html">R Package <em>genieclust</em> Reference</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">See Also</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://clustering-benchmarks.gagolewski.com">Clustering Benchmarks</a></li>
<li class="toctree-l1"><a class="reference external" href="https://datawranglingpy.gagolewski.com/">Data Wrangling in Python</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">What Is New in <em>genieclust</em></a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks_details.html">Benchmarks — Detailed Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarks_approx.html">Benchmarks — Approximate Method</a></li>
<li class="toctree-l1"><a class="reference internal" href="../z_bibliography.html">References</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">genieclust</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          



















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Basics</li>
    
    
      <li class="wy-breadcrumbs-aside">

        
        
        <a class="github-button" href="https://github.com/gagolews/genieclust" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star gagolews/genieclust on GitHub">GitHub</a>
        


        
      </li>
    
  </ul>

  
  <div class="rst-breadcrumbs-buttons" role="navigation" aria-label="breadcrumb navigation">
      
        <a href="sklearn_toy_example.html" class="btn btn-neutral float-right" title="Comparing Algorithms on Toy Datasets" accesskey="n">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
      
      
        <a href="../index.html" class="btn btn-neutral float-left" title="genieclust: Fast and Robust Hierarchical Clustering with Noise Point Detection" accesskey="p"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
      
  </div>
  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="basics">
<h1>Basics<a class="headerlink" href="#basics" title="Permalink to this heading"></a></h1>
<p><em>Genie</em> <span id="id1">[<a class="reference internal" href="../z_bibliography.html#id8" title="M. Gagolewski, M. Bartoszuk, and A. Cena. Genie: A new, fast, and outlier-resistant hierarchical clustering algorithm. Information Sciences, 363:8–23, 2016. doi:10.1016/j.ins.2016.05.003.">GBC16</a>]</span> is an agglomerative hierarchical clustering
algorithm that links clusters minding that
the Gini index (a popular measure of inequity used in, amongst others,
economics) of the cluster sizes should not go too far beyond a given threshold.
If this happens, instead of merging two closest clusters, a smallest cluster
is joined with its nearest neighbour.
In the following sections we’ll show that Genie frequently outperforms many other methods
in terms of clustering <a class="reference internal" href="benchmarks_ar.html"><span class="doc">quality</span></a> and <a class="reference internal" href="timings.html"><span class="doc">speed</span></a>.</p>
<p>Here are a few examples of basic interactions with the Python version
of the <cite>genieclust</cite> <span id="id2">[<a class="reference internal" href="../z_bibliography.html#id5" title="M. Gagolewski. genieclust: Fast and robust hierarchical clustering. SoftwareX, 15:100722, 2021. doi:10.1016/j.softx.2021.100722.">Gag21</a>]</span> package,
which can be installed from
<a class="reference external" href="https://pypi.org/project/genieclust/">PyPI</a>, e.g.,
via a call to <code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">genieclust</span></code> from the command line.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">genieclust</span>
</pre></div>
</div>
<section id="breaking-the-ice">
<h2>Breaking the Ice<a class="headerlink" href="#breaking-the-ice" title="Permalink to this heading"></a></h2>
<p>Let’s load an example benchmark set, <code class="docutils literal notranslate"><span class="pre">jain</span></code> <span id="id3">[<a class="reference internal" href="../z_bibliography.html#id28" title="A.K. Jain and M.H.C. Law. Data clustering: A user's dilemma. Lecture Notes in Computer Science, 3776:1–10, 2005.">JL05</a>]</span>, which  comes
with the true corresponding partition (as assigned by experts).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># see https://github.com/gagolews/genieclust/tree/master/devel/sphinx/weave</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="s2">&quot;jain&quot;</span>
<span class="c1"># Load an example 2D dataset:</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">.data.gz&quot;</span> <span class="o">%</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">ndmin</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Load the corresponding reference labels. The original labels are in {1,2,..,k}.</span>
<span class="c1"># We&#39;ll make them more Python-ish by subtracting 1.</span>
<span class="n">labels_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">.labels0.gz&quot;</span> <span class="o">%</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intp</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>

<span class="c1"># The number of unique labels gives the true cluster count:</span>
<span class="n">n_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels_true</span><span class="p">))</span>
</pre></div>
</div>
<p>A scatter plot of the dataset together with the reference labels:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">genieclust</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels_true</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> (n=</span><span class="si">%d</span><span class="s2">, true n_clusters=</span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">n_clusters</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default" id="id10">
<a class="reference internal image-reference" href="../_images/basics_basics-scatter_1.png"><img alt="../_images/basics_basics-scatter_1.png" src="../_images/basics_basics-scatter_1.png" style="width: 15cm;" /></a>
<figcaption>
<p><span class="caption-number">Figure 1 </span><span class="caption-text">Reference labels.</span><a class="headerlink" href="#id10" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>Let’s apply the Genie algorithm (with the default/recommended
<code class="docutils literal notranslate"><span class="pre">gini_threshold</span></code> parameter value). The <cite>genieclust</cite> package’s interface
is compatible with the one from the popular
<a class="reference external" href="https://scikit-learn.org/">scikit-learn</a> library <span id="id4">[<a class="reference internal" href="../z_bibliography.html#id32" title="F. Pedregosa and others. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12(85):2825–2830, 2011. URL: http://jmlr.org/papers/v12/pedregosa11a.html.">P+11</a>]</span>.
In particular, an object of class <cite>Genie</cite> is equipped with the
<cite>fit</cite> and <cite>fit_predict</cite> methods  <span id="id5">[<a class="reference internal" href="../z_bibliography.html#id31" title="L. Buitinck and others. API design for machine learning software: Experiences from the scikit-learn project. In ECML PKDD Workshop: Languages for Data Mining and Machine Learning, 108–122. 2013.">B+13</a>]</span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">genieclust</span><span class="o">.</span><span class="n">Genie</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">)</span>
<span class="n">labels_genie</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p>See the documentation of the <a class="reference internal" href="../genieclust_genie.html#genieclust.Genie" title="genieclust.Genie"><code class="xref py py-class docutils literal notranslate"><span class="pre">genieclust.Genie</span></code></a>class
for more details.</p>
<p>Plotting of the discovered partition:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">genieclust</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels_genie</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Genie (gini_threshold=</span><span class="si">%g</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="n">g</span><span class="o">.</span><span class="n">gini_threshold</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default" id="id11">
<a class="reference internal image-reference" href="../_images/basics_basics-plot-pred_1.png"><img alt="../_images/basics_basics-plot-pred_1.png" src="../_images/basics_basics-plot-pred_1.png" style="width: 15cm;" /></a>
<figcaption>
<p><span class="caption-number">Figure 2 </span><span class="caption-text">Labels predicted by Genie.</span><a class="headerlink" href="#id11" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>Nice.</p>
<p>A picture is worth a thousand words, but numbers are worth
millions of pictures. We can compare the resulting clustering with the reference
one by computing, for example, the confusion matrix.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute the confusion matrix (with pivoting)</span>
<span class="n">genieclust</span><span class="o">.</span><span class="n">compare_partitions</span><span class="o">.</span><span class="n">normalized_confusion_matrix</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_genie</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## array([[276,   0],</span>
<span class="c1">##        [  0,  97]])</span>
</pre></div>
</div>
<p>The above confusion matrix can be summarised by means of partition
similarity measures, like the Adjusted Rand Index (<code class="docutils literal notranslate"><span class="pre">ar</span></code>).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># See also: sklearn.metrics.adjusted_rand_score()</span>
<span class="n">genieclust</span><span class="o">.</span><span class="n">compare_partitions</span><span class="o">.</span><span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_genie</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## 1.0</span>
</pre></div>
</div>
<p>Which of course denotes a perfect match between these two.</p>
</section>
<section id="a-comparison-with-k-means">
<h2>A Comparison with k-means<a class="headerlink" href="#a-comparison-with-k-means" title="Permalink to this heading"></a></h2>
<p>For the sake of comparison, let’s apply the k-means algorithm on the same dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sklearn.cluster</span>
<span class="n">km</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">)</span>
<span class="n">labels_kmeans</span> <span class="o">=</span> <span class="n">km</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">genieclust</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels_kmeans</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;k-means&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default" id="id12">
<a class="reference internal image-reference" href="../_images/basics_basics-plot-km_1.png"><img alt="../_images/basics_basics-plot-km_1.png" src="../_images/basics_basics-plot-km_1.png" style="width: 15cm;" /></a>
<figcaption>
<p><span class="caption-number">Figure 3 </span><span class="caption-text">Labels predicted by k-means.</span><a class="headerlink" href="#id12" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>It is well known that the k-means algorithm can only split the input space into
convex regions (compare the notion of the
<a class="reference external" href="https://en.wikipedia.org/wiki/Voronoi_diagram">Voronoi diagrams</a>).
So we shouldn’t be much surprised with this result.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute the confusion matrix for the k-means output:</span>
<span class="n">genieclust</span><span class="o">.</span><span class="n">compare_partitions</span><span class="o">.</span><span class="n">normalized_confusion_matrix</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_kmeans</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## array([[197,  79],</span>
<span class="c1">##        [  1,  96]])</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># A cluster similarity measure for k-means:</span>
<span class="n">genieclust</span><span class="o">.</span><span class="n">compare_partitions</span><span class="o">.</span><span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_kmeans</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## 0.3241080446115835</span>
</pre></div>
</div>
<p>The adjusted Rand score of <span class="math notranslate nohighlight">\(\sim 0.3\)</span> indicates a far-from-perfect fit.</p>
</section>
<section id="a-comparison-with-hdbscan">
<h2>A Comparison with HDBSCAN*<a class="headerlink" href="#a-comparison-with-hdbscan" title="Permalink to this heading"></a></h2>
<p>Let’s also make a comparison against a version of the DBSCAN
<span id="id6">[<a class="reference internal" href="../z_bibliography.html#id30" title="M. Ester, H.P. Kriegel, J. Sander, and X. Xu. A density-based algorithm for discovering clusters in large spatial databases with noise. In Proc. KDD'96, pages 226–231. 1996.">EKSX96</a>, <a class="reference internal" href="../z_bibliography.html#id29" title="R.F. Ling. A probability theory of cluster analysis. Journal of the American Statistical Association, 68(341):159–164, 1973.">Lin73</a>]</span> algorithm. The original DBSCAN relies on a somewhat
magical <code class="docutils literal notranslate"><span class="pre">eps</span></code> parameter, which might be hard to tune in practice. However,
the <a class="reference external" href="https://github.com/scikit-learn-contrib/hdbscan">hdbscan</a> package
<span id="id7">[<a class="reference internal" href="../z_bibliography.html#id41" title="L. McInnes, J. Healy, and S. Astels. hdbscan: Hierarchical density based clustering. The Journal of Open Source Software, 2(11):205, 2017. doi:10.21105/joss.00205.">MHA17</a>]</span> implements its robustified variant
<span id="id8">[<a class="reference internal" href="../z_bibliography.html#id12" title="R.J.G.B. Campello, D. Moulavi, and J. Sander. Density-based clustering based on hierarchical density estimates. Lecture Notes in Computer Science, 7819:160–172, 2013. doi:10.1007/978-3-642-37456-2_14.">CMS13</a>]</span>, which makes the algorithm much more user-friendly.</p>
<p>Here are the clustering results with the <code class="docutils literal notranslate"><span class="pre">min_cluster_size</span></code> parameter
of 3, 5, 10, and 15:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">hdbscan</span>
<span class="n">mcs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mcs</span><span class="p">)):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">hdbscan</span><span class="o">.</span><span class="n">HDBSCAN</span><span class="p">(</span><span class="n">min_cluster_size</span><span class="o">=</span><span class="n">mcs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">labels_hdbscan</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">genieclust</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels_hdbscan</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;HDBSCAN (min_cluster_size=</span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="n">h</span><span class="o">.</span><span class="n">min_cluster_size</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default" id="id13">
<a class="reference internal image-reference" href="../_images/basics_basics-plot-hdbscan_1.png"><img alt="../_images/basics_basics-plot-hdbscan_1.png" src="../_images/basics_basics-plot-hdbscan_1.png" style="width: 15cm;" /></a>
<figcaption>
<p><span class="caption-number">Figure 4 </span><span class="caption-text">Labels predicted by HDBSCAN*.</span><a class="headerlink" href="#id13" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<dl class="simple">
<dt>Side note.</dt><dd><p>Gray plotting symbols denote “noise” points — we’ll get back to them
in another section; it turns out that the Genie algorithm is also equipped
with such a feature (on demand).</p>
</dd>
</dl>
<p>In HDBSCAN*,  <code class="docutils literal notranslate"><span class="pre">min_cluster_size</span></code> affects the “granularity”
of the obtained clusters. Its default value is set to:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hdbscan</span><span class="o">.</span><span class="n">HDBSCAN</span><span class="p">()</span><span class="o">.</span><span class="n">min_cluster_size</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## 5</span>
</pre></div>
</div>
<p>Unfortunately, we cannot easily guess how many clusters will be generated
by this method. At a first glance, it would seem that <code class="docutils literal notranslate"><span class="pre">min_cluster_size</span></code>
should lie somewhere between 10 and 15, but…</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mcs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mcs</span><span class="p">)):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">hdbscan</span><span class="o">.</span><span class="n">HDBSCAN</span><span class="p">(</span><span class="n">min_cluster_size</span><span class="o">=</span><span class="n">mcs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">labels_hdbscan</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">genieclust</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels_hdbscan</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;HDBSCAN (min_cluster_size=</span><span class="si">%d</span><span class="s2">)&quot;</span><span class="o">%</span><span class="n">h</span><span class="o">.</span><span class="n">min_cluster_size</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default" id="id14">
<a class="reference internal image-reference" href="../_images/basics_basics-plot-hdbscan2_1.png"><img alt="../_images/basics_basics-plot-hdbscan2_1.png" src="../_images/basics_basics-plot-hdbscan2_1.png" style="width: 15cm;" /></a>
<figcaption>
<p><span class="caption-number">Figure 5 </span><span class="caption-text">Labels predicted by HDBSCAN*.</span><a class="headerlink" href="#id14" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>Strangely enough, <code class="docutils literal notranslate"><span class="pre">min_cluster_size</span></code> of <span class="math notranslate nohighlight">\(11\)</span> generates 4 clusters,
whereas <span class="math notranslate nohighlight">\(11\pm 1\)</span> - only 3 of them.</p>
<p>On the other hand, the Genie algorithm belongs
to the group of <em>hierarchical agglomerative methods</em> — by definition
it’s able to generate
a sequence of <em>nested</em> partitions, which means that by
increasing <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code>, we split one and only one cluster
into two subgroups.
This makes the resulting partitions more stable.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ncl</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ncl</span><span class="p">)):</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">genieclust</span><span class="o">.</span><span class="n">Genie</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">ncl</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">labels_genie</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">genieclust</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels_genie</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Genie (n_clusters=</span><span class="si">%d</span><span class="s2">)&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">,))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default" id="id15">
<a class="reference internal image-reference" href="../_images/basics_basics-plot-genie2_1.png"><img alt="../_images/basics_basics-plot-genie2_1.png" src="../_images/basics_basics-plot-genie2_1.png" style="width: 15cm;" /></a>
<figcaption>
<p><span class="caption-number">Figure 6 </span><span class="caption-text">Labels predicted by Genie.</span><a class="headerlink" href="#id15" title="Permalink to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="dendrograms">
<h2>Dendrograms<a class="headerlink" href="#dendrograms" title="Permalink to this heading"></a></h2>
<p>Dendrogram plotting is possible with <cite>scipy.cluster.hierarchy</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.cluster.hierarchy</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">genieclust</span><span class="o">.</span><span class="n">Genie</span><span class="p">(</span><span class="n">compute_full_tree</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">linkage_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">g</span><span class="o">.</span><span class="n">children_</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">distances_</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">counts_</span><span class="p">])</span>
<span class="n">scipy</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">hierarchy</span><span class="o">.</span><span class="n">dendrogram</span><span class="p">(</span><span class="n">linkage_matrix</span><span class="p">,</span>
    <span class="n">show_leaf_counts</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">no_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default" id="id16">
<a class="reference internal image-reference" href="../_images/basics_basics-dendrogram-1_1.png"><img alt="../_images/basics_basics-dendrogram-1_1.png" src="../_images/basics_basics-dendrogram-1_1.png" style="width: 15cm;" /></a>
<figcaption>
<p><span class="caption-number">Figure 7 </span><span class="caption-text">Example dendrogram.</span><a class="headerlink" href="#id16" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>For a list of graphical parameters, refer to the function’s manual:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scipy</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">hierarchy</span><span class="o">.</span><span class="n">dendrogram</span><span class="p">(</span><span class="n">linkage_matrix</span><span class="p">,</span>
    <span class="n">truncate_mode</span><span class="o">=</span><span class="s2">&quot;lastp&quot;</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default" id="id17">
<a class="reference internal image-reference" href="../_images/basics_basics-dendrogram-2_1.png"><img alt="../_images/basics_basics-dendrogram-2_1.png" src="../_images/basics_basics-dendrogram-2_1.png" style="width: 15cm;" /></a>
<figcaption>
<p><span class="caption-number">Figure 8 </span><span class="caption-text">Another example dendrogram.</span><a class="headerlink" href="#id17" title="Permalink to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="further-reading">
<h2>Further Reading<a class="headerlink" href="#further-reading" title="Permalink to this heading"></a></h2>
<p>For more details, refer to the package’s API reference
manual: <a class="reference internal" href="../genieclust_genie.html#genieclust.Genie" title="genieclust.Genie"><code class="xref py py-class docutils literal notranslate"><span class="pre">genieclust.Genie</span></code></a>.</p>
<p>To learn more about Python, check out Marek’s open-access (free!) textbook
<a class="reference external" href="https://datawranglingpy.gagolewski.com/">Minimalist Data Wrangling in Python</a>
<span id="id9">[<a class="reference internal" href="../z_bibliography.html#id4" title="M. Gagolewski. Minimalist Data Wrangling with Python. Zenodo, Melbourne, 2022. ISBN 978-0-6455719-1-2. URL: https://datawranglingpy.gagolewski.com/, doi:10.5281/zenodo.6451068.">Gag22b</a>]</span>.</p>
</section>
</section>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="sklearn_toy_example.html" class="btn btn-neutral float-right" title="Comparing Algorithms on Toy Datasets" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="../index.html" class="btn btn-neutral float-left" title="genieclust: Fast and Robust Hierarchical Clustering with Noise Point Detection" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        Copyright &#169; 2018–2022 by <a href="https://www.gagolewski.com">Marek Gagolewski</a>. Some rights reserved. Licensed under <a href='https://creativecommons.org/licenses/by-nc-nd/4.0/'>CC BY-NC-ND 4.0</a>.

    Built with <a href="https://sphinx-doc.org/">Sphinx</a>
    and a customised <a href="https://github.com/rtfd/sphinx_rtd_theme">rtd</a>
    theme.
      <span class="lastupdated">
        Last updated on 2022-09-15T13:23:22+1000.
      </span>


    This site will never display any ads: it is a non-profit project.
    It does not collect any data.

    </p>
  </div> 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>